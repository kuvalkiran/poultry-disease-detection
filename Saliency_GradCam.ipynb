{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#SALIENCY MAPS"
      ],
      "metadata": {
        "id": "gFGtlcEjZJ4T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZB5MRNASCA89",
        "outputId": "51af19ac-d0fb-4b2b-c08e-7cf211fec016"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/mydrive; to attempt to forcibly remount, call drive.mount(\"/content/mydrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/mydrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from pathlib import Path\n",
        "import os.path\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import seaborn as sns\n",
        "sns.set_style('darkgrid')\n",
        "import shutil\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Dense, Activation, Dropout, Conv2D, MaxPooling2D, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam, Adamax\n",
        "from tensorflow.keras.metrics import categorical_crossentropy\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.models import Model\n",
        "from IPython.display import Image, display\n",
        "import matplotlib.cm as cm\n",
        "import PIL\n",
        "import logging\n",
        "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
        "import warnings\n",
        "# Adjusting the maximum number of columns for the DataFrame\n",
        "pd.options.display.max_columns = None\n",
        "pd.options.display.max_rows = 90\n",
        "warnings.simplefilter(\"ignore\")"
      ],
      "metadata": {
        "id": "1vbgP6OcCG_T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def input_img(path):\n",
        "    image = tf.image.decode_image(tf.io.read_file(path))\n",
        "    image = preprocess_image(image)\n",
        "    return image\n",
        "\n",
        "def preprocess_image(image):\n",
        "    # Resize image to 224x224\n",
        "    image = tf.image.resize(image, [224, 224])\n",
        "    # Ensure the image is in RGB format\n",
        "    if image.shape[-1] != 3:\n",
        "        image = tf.image.grayscale_to_rgb(image)\n",
        "    return image\n",
        "\n",
        "def normalize_image(img):\n",
        "    grads_norm = img[:,:,0]+ img[:,:,1]+ img[:,:,2]\n",
        "    grads_norm = (grads_norm - tf.reduce_min(grads_norm))/ (tf.reduce_max(grads_norm)- tf.reduce_min(grads_norm))\n",
        "    return grads_norm\n",
        "\n",
        "def plot_maps(img1, img2, vmin=0.3, vmax=0.7, mix_val=2):\n",
        "    f = plt.figure(figsize=(15,45))\n",
        "    plt.subplot(1,3,1)\n",
        "    plt.imshow(img1, vmin=vmin, vmax=vmax, cmap=\"ocean\")\n",
        "    plt.axis(\"off\")\n",
        "    plt.title('Saliency Map')\n",
        "    plt.subplot(1,3,2)\n",
        "    plt.imshow(img2, cmap=\"ocean\")\n",
        "    plt.axis(\"off\")\n",
        "    plt.title('Input Image')\n",
        "    plt.subplot(1,3,3)\n",
        "    plt.imshow(img1*mix_val+img2/mix_val, cmap=\"ocean\" )\n",
        "    plt.axis(\"off\")\n",
        "    plt.title('Overlayed Image')\n",
        "\n",
        "# Load your trained model\n",
        "model_path =  # Update with model path\n",
        "test_model = tf.keras.models.load_model(model_path)\n",
        "\n",
        "# Define the path to the image on your Google Drive\n",
        "img_path =  # Update with test image\n",
        "\n",
        "# Read and preprocess the image\n",
        "input_img = input_img(img_path)\n",
        "input_img = tf.expand_dims(input_img, axis=0)\n",
        "\n",
        "# Make predictions using your model\n",
        "result = test_model.predict(input_img)\n",
        "max_idx = np.argmax(result,axis = 1)\n",
        "print(\"Predicted class indices:\", max_idx)\n",
        "\n",
        "# Generate saliency map\n",
        "with tf.GradientTape() as tape:\n",
        "    tape.watch(input_img)\n",
        "    result = test_model(input_img)\n",
        "    max_score = result[0,max_idx[0]]\n",
        "\n",
        "grads = tape.gradient(max_score, input_img)\n",
        "plot_maps(normalize_image(grads[0]), normalize_image(input_img[0]))\n"
      ],
      "metadata": {
        "id": "cbMU6Fd_Cbv_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#GRADCAM"
      ],
      "metadata": {
        "id": "FZMeIsIWZH_d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_model.summary()"
      ],
      "metadata": {
        "id": "_P0WYJz2QQ8f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "\n",
        "img_size = (224, 224)\n",
        "\n",
        "def preprocess_image(image):\n",
        "    # Resize image to 224x224\n",
        "    image = tf.image.resize(image, [224, 224])\n",
        "    # Ensure the image is in RGB format\n",
        "    if image.shape[-1] != 3:\n",
        "        image = tf.image.grayscale_to_rgb(image)\n",
        "    return image\n",
        "\n",
        "def normalize_image(img):\n",
        "    grads_norm = img[:,:,0]+ img[:,:,1]+ img[:,:,2]\n",
        "    grads_norm = (grads_norm - tf.reduce_min(grads_norm))/ (tf.reduce_max(grads_norm)- tf.reduce_min(grads_norm))\n",
        "    return grads_norm\n",
        "\n",
        "last_conv_layer_name = \"Conv_1\"\n",
        "\n",
        "## The local path to our target image\n",
        "\n",
        "input_img1 = # Update with test image\n",
        "\n",
        "display(Image(input_img1))\n",
        "\n",
        "def get_img_array(img_path, size):\n",
        "    ## `img` is a PIL image\n",
        "    img = keras.utils.load_img(img_path, target_size=size)\n",
        "    array = keras.utils.img_to_array(img)\n",
        "    ## We add a dimension to transform our array into a \"batch\"\n",
        "    array = np.expand_dims(array, axis=0)\n",
        "    return array\n",
        "\n",
        "\n",
        "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
        "    ## First, we create a model that maps the input image to the activations\n",
        "    ## of the last conv layer as well as the output predictions\n",
        "    grad_model = keras.models.Model(\n",
        "        model.inputs, [model.get_layer(last_conv_layer_name).output, model.output]\n",
        "    )\n",
        "\n",
        "    ## Then, we compute the gradient of the top predicted class for our input image\n",
        "    ## for the activations of the last conv layer\n",
        "    with tf.GradientTape() as tape:\n",
        "        last_conv_layer_output, preds = grad_model(img_array)\n",
        "        if pred_index is None:\n",
        "            pred_index = tf.argmax(preds[0])\n",
        "        class_channel = preds[:, pred_index]\n",
        "\n",
        "    ## We are doing transfer learning on last layer\n",
        "    grads = tape.gradient(class_channel, last_conv_layer_output)\n",
        "\n",
        "    ## This is a vector where each entry is the mean intensity of the gradient\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "\n",
        "    ## calculates a heatmap highlighting the regions of importance in an image\n",
        "    ## for a specific\n",
        "    ## predicted class by combining the output of the last convolutional layer\n",
        "    ## with the pooled gradients.\n",
        "    last_conv_layer_output = last_conv_layer_output[0]\n",
        "    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n",
        "    heatmap = tf.squeeze(heatmap)\n",
        "\n",
        "    ## For visualization purpose\n",
        "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
        "    return heatmap.numpy()"
      ],
      "metadata": {
        "id": "FEULZdB3QP2B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Preparing the image\n",
        "img_array = preprocess_image(get_img_array(input_img1, size=img_size))\n",
        "\n",
        "preds = test_model.predict(img_array)\n",
        "print(\"Predicted of image:\", preds)\n",
        "\n",
        "## Generate class activation heatmap\n",
        "heatmap = make_gradcam_heatmap(img_array, test_model, last_conv_layer_name)\n",
        "\n",
        "## visulization of heatmap\n",
        "plt.matshow(heatmap)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GNlXK9U9Qg9J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_and_display_gradcam(img_path, heatmap, cam_path=\"save_cam_image.jpg\", alpha=0.4):\n",
        "    ## Loading the original image\n",
        "    img = keras.utils.load_img(img_path)\n",
        "    img = keras.utils.img_to_array(img)\n",
        "\n",
        "    ## Rescale heatmap to a range 0-255\n",
        "    heatmap = np.uint8(255 * heatmap)\n",
        "\n",
        "    ## Use jet colormap to colorize heatmap\n",
        "    jet = mpl.colormaps[\"jet\"]\n",
        "\n",
        "    jet_colors = jet(np.arange(256))[:, :3]\n",
        "    jet_heatmap = jet_colors[heatmap]\n",
        "\n",
        "    ## Create an image with RGB colorized heatmap\n",
        "    jet_heatmap = keras.utils.array_to_img(jet_heatmap)\n",
        "    jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n",
        "    jet_heatmap = keras.utils.img_to_array(jet_heatmap)\n",
        "\n",
        "    ## Superimpose the heatmap on original image\n",
        "    Superimposed_img = jet_heatmap * alpha + img\n",
        "    Superimposed_img = keras.utils.array_to_img(Superimposed_img)\n",
        "\n",
        "    ## Save the superimposed image\n",
        "    Superimposed_img.save(cam_path)\n",
        "\n",
        "    ## Displaying Grad CAM\n",
        "    display(Image(cam_path))\n",
        "\n",
        "\n",
        "save_and_display_gradcam(input_img1, heatmap)"
      ],
      "metadata": {
        "id": "qbf6vFCJQmmB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}